{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e12c27-8b09-4c58-be79-ae111860f3df",
   "metadata": {},
   "source": [
    "# CMSC 197: Na√Øve Bayes Spam Classifier\n",
    "### Christian Dale P. Celestial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a47bc20-ebef-4d1d-bace-ae7aff595fe9",
   "metadata": {},
   "source": [
    "***\n",
    "## Preprocessing\n",
    "Split the dataset into three(3) groups: training set for ham, training set for spam, and the testing set.\n",
    "- Folders 00-70: Train set\n",
    "- Folders 71-127: Test set\n",
    "\n",
    "Train sets included 21, 300 emails and 16, 522 emails for the test set. The labels contained in the label file was attached to its corresponding email.\n",
    "Remove words from the document which may not contribute to the information we want to extract. These includes dropping the alphanumeric characters and punctuation marks.<br>\n",
    "\n",
    "Also, remove stop words, more popularly known as meaningless words, from the email body since those words are not useful in classification as well as reduce the dimensionality of the dictionary. A text file with filename, **stop_words.txt**, is also uploaded in LMS.<br>\n",
    "\n",
    "After doing these methods, extract a list of unique words from the training set along with its summed number of occurrences from the spam and ham set. To limit the cardinality of the dictionary, we can extract only the 10000 most common words (common means that these words have the highest frequencies/occurences in the dataset).<br>\n",
    "\n",
    "*Note: You can use the ‚Äúemail‚Äù package in python to extract the body of the email. Watch out for \n",
    "problems in encodings and use the email charset aliases accordingly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fad8ebc-07b0-4676-b533-bd1853e22627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bb': 16733,\n",
       " 'will': 10479,\n",
       " 'board': 5012,\n",
       " 'price': 4058,\n",
       " 'list': 3897,\n",
       " 'nil': 3830,\n",
       " 'email': 3741,\n",
       " 'help': 3652,\n",
       " 'subject': 3552,\n",
       " 'time': 3537,\n",
       " 'dont': 3534,\n",
       " 'send': 3519,\n",
       " 'company': 3508,\n",
       " 'adobe': 3490,\n",
       " 'crustl': 3295,\n",
       " 'message': 3256,\n",
       " 'received': 3046,\n",
       " 'program': 2965,\n",
       " 'work': 2738,\n",
       " 'wrote': 2671,\n",
       " 'ms': 2603,\n",
       " 'well': 2595,\n",
       " 'gold': 2585,\n",
       " 'professional': 2455,\n",
       " 'university': 2422,\n",
       " 'good': 2419,\n",
       " 'problem': 2349,\n",
       " 'number': 2263,\n",
       " 'file': 2235,\n",
       " 'handyboard': 2219,\n",
       " 'hb': 2191,\n",
       " 'microsoft': 2063,\n",
       " 'windows': 2059,\n",
       " 'add': 2041,\n",
       " 'office': 2021,\n",
       " 'studies': 1972,\n",
       " 'code': 1909,\n",
       " 'womens': 1887,\n",
       " 'find': 1860,\n",
       " 'pro': 1848,\n",
       " 'current': 1835,\n",
       " 'info': 1830,\n",
       " 'news': 1803,\n",
       " 'de': 1765,\n",
       " 'read': 1755,\n",
       " 'motor': 1744,\n",
       " 'power': 1731,\n",
       " 'ic': 1731,\n",
       " 'people': 1682,\n",
       " 'great': 1680,\n",
       " 'save': 1670,\n",
       " 'call': 1662,\n",
       " 'system': 1659,\n",
       " 'fax': 1656,\n",
       " 'corp': 1651,\n",
       " 'handy': 1635,\n",
       " 'today': 1628,\n",
       " 'text': 1625,\n",
       " 'unsubscribe': 1622,\n",
       " 'data': 1621,\n",
       " 'bit': 1607,\n",
       " 'ive': 1598,\n",
       " 'address': 1590,\n",
       " 'days': 1555,\n",
       " 'stock': 1551,\n",
       " 'set': 1523,\n",
       " 'pt': 1500,\n",
       " 'development': 1495,\n",
       " 'mail': 1479,\n",
       " 'best': 1476,\n",
       " 'port': 1425,\n",
       " 'china': 1419,\n",
       " 'majordomovimsedu': 1386,\n",
       " 'contenttype': 1380,\n",
       " 'control': 1373,\n",
       " 'free': 1365,\n",
       " 'better': 1363,\n",
       " 'site': 1358,\n",
       " 'web': 1354,\n",
       " 'computer': 1348,\n",
       " 'rating': 1348,\n",
       " 'additional': 1339,\n",
       " 'reviews': 1335,\n",
       " 'xp': 1335,\n",
       " 'life': 1327,\n",
       " 'retail': 1320,\n",
       " 'cart': 1304,\n",
       " 'money': 1293,\n",
       " 'day': 1291,\n",
       " 'robot': 1289,\n",
       " 'big': 1279,\n",
       " 'offer': 1279,\n",
       " 'body': 1248,\n",
       " 'oil': 1239,\n",
       " 'market': 1221,\n",
       " 'ra': 1219,\n",
       " 'textplain': 1218,\n",
       " 'experience': 1217,\n",
       " 'td': 1214,\n",
       " 'energy': 1212,\n",
       " 'messages': 1206,\n",
       " 'software': 1204,\n",
       " 'project': 1184,\n",
       " 'mimeversion': 1180,\n",
       " 'years': 1171,\n",
       " 'version': 1166,\n",
       " 'gas': 1163,\n",
       " 'cantex': 1160,\n",
       " 'service': 1159,\n",
       " 'wmstlumddumdedu': 1156,\n",
       " 'thu': 1155,\n",
       " 'week': 1153,\n",
       " 'things': 1145,\n",
       " 'motors': 1141,\n",
       " 'post': 1130,\n",
       " 'long': 1130,\n",
       " 'problems': 1119,\n",
       " 'unicode': 1097,\n",
       " 'start': 1094,\n",
       " 'pm': 1092,\n",
       " 'going': 1091,\n",
       " 'order': 1091,\n",
       " 'real': 1091,\n",
       " 'doesnt': 1090,\n",
       " 'replyto': 1088,\n",
       " 'sender': 1078,\n",
       " 'question': 1072,\n",
       " 'httphyakushowcomtada': 1072,\n",
       " 'works': 1065,\n",
       " 'thing': 1065,\n",
       " 'forward': 1064,\n",
       " 'high': 1061,\n",
       " 'files': 1060,\n",
       " 'based': 1058,\n",
       " 'international': 1051,\n",
       " 'windowtext': 1040,\n",
       " 'digital': 1037,\n",
       " 'serial': 1034,\n",
       " 'yew': 1030,\n",
       " 'mon': 1028,\n",
       " 'support': 1027,\n",
       " 'campaign': 1027,\n",
       " 'tue': 1024,\n",
       " 'expansion': 1024,\n",
       " 'sep': 1018,\n",
       " 'special': 1015,\n",
       " 'space': 1014,\n",
       " 'working': 1006,\n",
       " 'point': 996,\n",
       " 'check': 992,\n",
       " 'plan': 990,\n",
       " 'department': 988,\n",
       " 'science': 987,\n",
       " 'full': 985,\n",
       " 'video': 984,\n",
       " 'cant': 983,\n",
       " 'jul': 982,\n",
       " 'aug': 980,\n",
       " 'potential': 980,\n",
       " 'interested': 975,\n",
       " 'txtadd': 965,\n",
       " 'original': 958,\n",
       " 'output': 956,\n",
       " 'infinex': 956,\n",
       " 'running': 946,\n",
       " 'second': 937,\n",
       " 'report': 937,\n",
       " 'small': 934,\n",
       " 'fri': 931,\n",
       " 'error': 925,\n",
       " 'charsetusascii': 925,\n",
       " 'input': 914,\n",
       " 'technology': 907,\n",
       " 'messageid': 905,\n",
       " 'short': 901,\n",
       " 'contact': 899,\n",
       " 'timeout': 891,\n",
       " 'claims': 890,\n",
       " 'fred': 889,\n",
       " 'commands': 886,\n",
       " 'change': 884,\n",
       " 'sensor': 867,\n",
       " 'exploration': 864,\n",
       " 'students': 858,\n",
       " 'business': 856,\n",
       " 'dear': 849,\n",
       " 'low': 843,\n",
       " 'release': 842,\n",
       " 'esmtp': 840,\n",
       " 'provide': 838,\n",
       " 'phone': 837,\n",
       " 'place': 835,\n",
       " 'design': 835,\n",
       " 'online': 835,\n",
       " 'receive': 832,\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa': 829,\n",
       " 'hope': 828,\n",
       " 'crustlvimsedu': 826,\n",
       " 'mm': 824,\n",
       " 'battery': 822,\n",
       " 'currently': 820,\n",
       " 'option': 817,\n",
       " 'hello': 817,\n",
       " 'download': 816,\n",
       " 'course': 815,\n",
       " 'fine': 813,\n",
       " 'include': 812,\n",
       " 'ir': 812,\n",
       " 'fast': 805,\n",
       " 'year': 805,\n",
       " 'questions': 798,\n",
       " 'application': 793,\n",
       " 'html': 791,\n",
       " 'plain': 790,\n",
       " 'servo': 790,\n",
       " 'three': 788,\n",
       " 'access': 787,\n",
       " 'light': 784,\n",
       " 'test': 782,\n",
       " 'apr': 781,\n",
       " 'group': 778,\n",
       " 'st': 775,\n",
       " 'turn': 775,\n",
       " 'handyboardmediamitedu': 774,\n",
       " 'approved': 773,\n",
       " 'pin': 772,\n",
       " 'mode': 771,\n",
       " 'internet': 771,\n",
       " 'idea': 770,\n",
       " 'pdt': 770,\n",
       " 'form': 770,\n",
       " 'note': 770,\n",
       " 'memory': 764,\n",
       " 'chip': 763,\n",
       " 'systems': 757,\n",
       " 'write': 754,\n",
       " 'kind': 753,\n",
       " 'website': 752,\n",
       " 'sonar': 749,\n",
       " 'technologies': 748,\n",
       " 'women': 745,\n",
       " 'starting': 744,\n",
       " 'side': 739,\n",
       " 'pine': 738,\n",
       " 'standard': 732,\n",
       " 'times': 731,\n",
       " 'case': 730,\n",
       " 'effects': 730,\n",
       " 'edt': 728,\n",
       " 'voltage': 725,\n",
       " 'apple': 723,\n",
       " 'services': 717,\n",
       " 'opportunities': 715,\n",
       " 'store': 714,\n",
       " 'br': 713,\n",
       " 'prospect': 712,\n",
       " 'lcd': 708,\n",
       " 'contenttransferencoding': 707,\n",
       " 'archives': 705,\n",
       " 'including': 704,\n",
       " 'sun': 703,\n",
       " 'press': 699,\n",
       " 'statements': 695,\n",
       " 'bldkb': 693,\n",
       " 'john': 690,\n",
       " 'seismic': 688,\n",
       " 'type': 684,\n",
       " 'int': 682,\n",
       " 'golden': 679,\n",
       " 'future': 679,\n",
       " 'watch': 679,\n",
       " 'companys': 679,\n",
       " 'analog': 678,\n",
       " 'complete': 673,\n",
       " 'pleased': 672,\n",
       " 'simply': 666,\n",
       " 'investors': 664,\n",
       " 'buy': 663,\n",
       " 'large': 661,\n",
       " 'mar': 661,\n",
       " 'tel': 660,\n",
       " 'sensors': 658,\n",
       " 'source': 657,\n",
       " 'book': 657,\n",
       " 'lot': 655,\n",
       " 'class': 655,\n",
       " 'field': 654,\n",
       " 'pc': 651,\n",
       " 'longer': 648,\n",
       " 'hc': 646,\n",
       " 'production': 642,\n",
       " 'rolex': 642,\n",
       " 'agreement': 637,\n",
       " 'answer': 636,\n",
       " 'usa': 634,\n",
       " 'nov': 634,\n",
       " 'delay': 634,\n",
       " 'launch': 634,\n",
       " 'friday': 634,\n",
       " 'process': 633,\n",
       " 'simple': 630,\n",
       " 'main': 630,\n",
       " 'issue': 627,\n",
       " 'allow': 626,\n",
       " 'return': 624,\n",
       " 'httplovematchbzpc': 620,\n",
       " 'advance': 618,\n",
       " 'word': 618,\n",
       " 'sincerely': 618,\n",
       " 'mailing': 615,\n",
       " 'san': 615,\n",
       " 'wrong': 609,\n",
       " 'characters': 609,\n",
       " 'joint': 609,\n",
       " 'drive': 603,\n",
       " 'monday': 603,\n",
       " 'connected': 601,\n",
       " 'april': 600,\n",
       " 'general': 599,\n",
       " 'thought': 599,\n",
       " 'programs': 598,\n",
       " 'school': 596,\n",
       " 'true': 595,\n",
       " 'cs': 595,\n",
       " 'engineering': 594,\n",
       " 'committee': 594,\n",
       " 'discussion': 593,\n",
       " 'function': 592,\n",
       " 'fact': 592,\n",
       " 'texas': 590,\n",
       " 'private': 589,\n",
       " 'example': 588,\n",
       " 'smtp': 588,\n",
       " 'common': 586,\n",
       " 'third': 586,\n",
       " 'lines': 585,\n",
       " 'connect': 585,\n",
       " 'cc': 585,\n",
       " 'jan': 584,\n",
       " 'extension': 584,\n",
       " 'hours': 584,\n",
       " 'size': 583,\n",
       " 'visit': 583,\n",
       " 'matter': 581,\n",
       " 'httpwwwvimsedujeffarchivehtm': 581,\n",
       " 'ventures': 580,\n",
       " 'build': 579,\n",
       " 'limited': 579,\n",
       " 'canyon': 579,\n",
       " 'led': 579,\n",
       " 'starshipdesignlistsuoregonedu': 579,\n",
       " 'corporation': 577,\n",
       " 'left': 576,\n",
       " 'interest': 575,\n",
       " 'ill': 575,\n",
       " 'solution': 574,\n",
       " 'easy': 574,\n",
       " 'swath': 574,\n",
       " 'natural': 573,\n",
       " 'device': 569,\n",
       " 'history': 569,\n",
       " 'collection': 569,\n",
       " 'reading': 566,\n",
       " 'ago': 565,\n",
       " 'display': 565,\n",
       " 'character': 564,\n",
       " 'mining': 564,\n",
       " 'details': 563,\n",
       " 'dec': 563,\n",
       " 'conference': 563,\n",
       " 'product': 562,\n",
       " 'directly': 562,\n",
       " 'shipping': 562,\n",
       " 'share': 561,\n",
       " 'numbers': 561,\n",
       " 'interface': 561,\n",
       " 'area': 560,\n",
       " 'student': 560,\n",
       " 'machine': 554,\n",
       " 'started': 554,\n",
       " 'edition': 548,\n",
       " 'hard': 547,\n",
       " 'signal': 547,\n",
       " 'library': 545,\n",
       " 'speed': 543,\n",
       " 'shares': 542,\n",
       " 'processing': 541,\n",
       " 'companies': 538,\n",
       " 'announces': 538,\n",
       " 'normal': 536,\n",
       " 'didnt': 536,\n",
       " 'beeddddeeb': 536,\n",
       " 'pretty': 535,\n",
       " 'west': 535,\n",
       " 'account': 534,\n",
       " 'degree': 533,\n",
       " 'properties': 533,\n",
       " 'men': 532,\n",
       " 'starshipdesign': 532,\n",
       " 'dmdx': 532,\n",
       " 'north': 530,\n",
       " 'circuit': 530,\n",
       " 'shareholder': 530,\n",
       " 'manager': 529,\n",
       " 'dr': 527,\n",
       " 'close': 527,\n",
       " 'building': 526,\n",
       " 'increase': 524,\n",
       " 'update': 520,\n",
       " 'play': 518,\n",
       " 'prices': 516,\n",
       " 'te': 515,\n",
       " 'turned': 512,\n",
       " 'sharp': 512,\n",
       " 'local': 511,\n",
       " 'june': 511,\n",
       " 'link': 511,\n",
       " 'independent': 511,\n",
       " 'watches': 511,\n",
       " 'top': 510,\n",
       " 'click': 509,\n",
       " 'trade': 509,\n",
       " 'servos': 508,\n",
       " 'box': 506,\n",
       " 'management': 506,\n",
       " 'move': 506,\n",
       " 'expect': 505,\n",
       " 'cpu': 505,\n",
       " 'havent': 503,\n",
       " 'luck': 503,\n",
       " 'gmt': 503,\n",
       " 'position': 501,\n",
       " 'correct': 501,\n",
       " 'supply': 500,\n",
       " 'located': 500,\n",
       " 'mike': 499,\n",
       " 'load': 499,\n",
       " 'server': 498,\n",
       " 'deal': 497,\n",
       " 'range': 496,\n",
       " 'college': 495,\n",
       " 'island': 494,\n",
       " 'reply': 493,\n",
       " 'feel': 490,\n",
       " 'total': 489,\n",
       " 'meeting': 489,\n",
       " 'needed': 488,\n",
       " 'reference': 488,\n",
       " 'sell': 488,\n",
       " 'quality': 487,\n",
       " 'la': 487,\n",
       " 'called': 486,\n",
       " 'making': 485,\n",
       " 'open': 485,\n",
       " 'format': 485,\n",
       " 'photoshop': 485,\n",
       " 'required': 484,\n",
       " 'choice': 484,\n",
       " 'stuff': 483,\n",
       " 'language': 481,\n",
       " 'shareholders': 481,\n",
       " 'operations': 480,\n",
       " 'remember': 479,\n",
       " 'style': 479,\n",
       " 'parts': 476,\n",
       " 'cwtd': 476,\n",
       " 'returnpath': 475,\n",
       " 'response': 475,\n",
       " 'dc': 475,\n",
       " 'weeks': 472,\n",
       " 'venture': 471,\n",
       " 'issues': 470,\n",
       " 'appreciated': 468,\n",
       " 'center': 468,\n",
       " 'copy': 467,\n",
       " 'ports': 467,\n",
       " 'driver': 466,\n",
       " 'interesting': 465,\n",
       " 'result': 465,\n",
       " 'level': 465,\n",
       " 'paper': 464,\n",
       " 'unicodeunicodeorg': 464,\n",
       " 'network': 462,\n",
       " 'developing': 462,\n",
       " 'communication': 462,\n",
       " 'expected': 461,\n",
       " 'opportunity': 461,\n",
       " 'cost': 460,\n",
       " 'greko': 460,\n",
       " 'widthd': 460,\n",
       " 'multiple': 459,\n",
       " 'head': 458,\n",
       " 'media': 457,\n",
       " 'sat': 456,\n",
       " 'tenure': 456,\n",
       " 'acrobat': 456,\n",
       " 'valigndtop': 456,\n",
       " 'suggestions': 455,\n",
       " 'premiere': 455,\n",
       " 'lego': 455,\n",
       " 'fully': 454,\n",
       " 'record': 453,\n",
       " 'wondering': 453,\n",
       " 'credit': 453,\n",
       " 'written': 451,\n",
       " 'ascii': 451,\n",
       " 'sector': 451,\n",
       " 'tuesday': 450,\n",
       " 'lose': 449,\n",
       " 'antonio': 448,\n",
       " 'programming': 446,\n",
       " 'mhz': 446,\n",
       " 'bjegsb': 446,\n",
       " 'water': 445,\n",
       " 'happy': 444,\n",
       " 'knowledge': 444,\n",
       " 'announced': 444,\n",
       " 'color': 443,\n",
       " 'august': 443,\n",
       " 'interactive': 443,\n",
       " 'request': 442,\n",
       " 'investment': 442,\n",
       " 'bestsellers': 441,\n",
       " 'loan': 440,\n",
       " 'ownerstarshipdesignlistsuoregonedu': 440,\n",
       " 'darkwinguoregonedu': 440,\n",
       " 'phd': 439,\n",
       " 'unicodeorg': 438,\n",
       " 'dvd': 438,\n",
       " 'inreplyto': 437,\n",
       " 'effective': 437,\n",
       " 'command': 436,\n",
       " 'hardware': 434,\n",
       " 'verified': 434,\n",
       " 'encore': 433,\n",
       " 'names': 432,\n",
       " 'audition': 432,\n",
       " 'books': 431,\n",
       " 'screen': 430,\n",
       " 'jonathan': 430,\n",
       " 'july': 429,\n",
       " 'person': 428,\n",
       " 'month': 428,\n",
       " 'pins': 427,\n",
       " 'cialis': 427,\n",
       " 'boards': 426,\n",
       " 'clixme': 426,\n",
       " 'members': 425,\n",
       " 'bad': 425,\n",
       " 'aa': 424,\n",
       " 'huge': 424,\n",
       " 'classdmsonormalif': 424,\n",
       " 'supportemptyparasnbspendifspan': 424,\n",
       " 'styledfontsizeptmsobidifontsizeptopopspan': 424,\n",
       " 'american': 423,\n",
       " 'key': 422,\n",
       " 'soft': 422,\n",
       " 'pcode': 422,\n",
       " 'major': 421,\n",
       " 'job': 421,\n",
       " 'president': 421,\n",
       " 'term': 418,\n",
       " 'series': 417,\n",
       " 'rate': 417,\n",
       " 'talk': 417,\n",
       " 'papers': 417,\n",
       " 'products': 416,\n",
       " 'isnt': 415,\n",
       " 'martin': 415,\n",
       " 'register': 415,\n",
       " 'america': 414,\n",
       " 'trace': 414,\n",
       " 'drilling': 414,\n",
       " 'exciting': 413,\n",
       " 'industry': 412,\n",
       " 'user': 412,\n",
       " 'south': 412,\n",
       " 'national': 412,\n",
       " 'offers': 411,\n",
       " 'risk': 411,\n",
       " 'val': 411,\n",
       " 'director': 411,\n",
       " 'texada': 410,\n",
       " 'resources': 409,\n",
       " 'msfd': 409,\n",
       " 'unix': 408,\n",
       " 'tr': 407,\n",
       " 'difficult': 406,\n",
       " 'xmailer': 406,\n",
       " 'institute': 405,\n",
       " 'held': 404,\n",
       " 'sex': 404,\n",
       " 'allows': 403,\n",
       " 'pay': 402,\n",
       " 'focus': 401,\n",
       " 'applications': 400,\n",
       " 'friend': 400,\n",
       " 'wont': 399,\n",
       " 'couple': 397,\n",
       " 'understand': 397,\n",
       " 'acres': 396,\n",
       " 'cr': 395,\n",
       " 'cable': 395,\n",
       " 'split': 394,\n",
       " 'changes': 393,\n",
       " 'card': 393,\n",
       " 'charge': 393,\n",
       " 'single': 392,\n",
       " 'advice': 392,\n",
       " 'orgasms': 391,\n",
       " 'ideas': 390,\n",
       " 'higher': 389,\n",
       " 'directors': 388,\n",
       " 'green': 386,\n",
       " 'graduate': 385,\n",
       " 'writing': 384,\n",
       " 'red': 384,\n",
       " 'country': 381,\n",
       " 'create': 380,\n",
       " 'volume': 380,\n",
       " 'writes': 380,\n",
       " 'coming': 380,\n",
       " 'bmpinterrogdelay': 379,\n",
       " 'unit': 378,\n",
       " 'bank': 378,\n",
       " 'trading': 378,\n",
       " 'room': 376,\n",
       " 'values': 376,\n",
       " 'jp': 376,\n",
       " 'cgdc': 376,\n",
       " 'man': 375,\n",
       " 'enjoy': 373,\n",
       " 'delivery': 373,\n",
       " 'inform': 373,\n",
       " 'frank': 373,\n",
       " 'march': 372,\n",
       " 'ii': 369,\n",
       " 'users': 369,\n",
       " 'securities': 367,\n",
       " 'routines': 366,\n",
       " 'jun': 366,\n",
       " 'feb': 365,\n",
       " 'void': 365,\n",
       " 'outputs': 365,\n",
       " 'chips': 364,\n",
       " 'licensed': 364,\n",
       " 'techniques': 363,\n",
       " 'continue': 362,\n",
       " 'comments': 362,\n",
       " 'bulk': 362,\n",
       " 'est': 362,\n",
       " 'david': 361,\n",
       " 'exactly': 361,\n",
       " 'url': 361,\n",
       " 'professor': 361,\n",
       " 'species': 360,\n",
       " 'addresses': 360,\n",
       " 'reason': 360,\n",
       " 'youll': 359,\n",
       " 'worked': 358,\n",
       " 'remove': 358,\n",
       " 'sound': 358,\n",
       " 'marketing': 358,\n",
       " 'switch': 356,\n",
       " 'eye': 356,\n",
       " 'early': 354,\n",
       " 'ross': 354,\n",
       " 'house': 353,\n",
       " 'linux': 353,\n",
       " 'mobile': 353,\n",
       " 'climb': 353,\n",
       " 'radio': 351,\n",
       " 'degrees': 351,\n",
       " 'nice': 350,\n",
       " 'customer': 350,\n",
       " 'health': 350,\n",
       " 'undertaken': 350,\n",
       " 'bbb': 350,\n",
       " 'asked': 349,\n",
       " 'love': 349,\n",
       " 'lottery': 349,\n",
       " 'cash': 348,\n",
       " 'methods': 348,\n",
       " 'bytes': 347,\n",
       " 'geophysical': 347,\n",
       " 'precedence': 347,\n",
       " 'ground': 346,\n",
       " 'hot': 346,\n",
       " 'mineral': 346,\n",
       " 'search': 345,\n",
       " 'directory': 344,\n",
       " 'global': 344,\n",
       " 'public': 343,\n",
       " 'unique': 343,\n",
       " 'spi': 343,\n",
       " 'enhancing': 341,\n",
       " 'manual': 340,\n",
       " 'minutes': 340,\n",
       " 'formula': 340,\n",
       " 'base': 339,\n",
       " 'oct': 338,\n",
       " 'ctxe': 338,\n",
       " 'confirm': 337,\n",
       " 'resistor': 337,\n",
       " 'consider': 336,\n",
       " 'weight': 336,\n",
       " 'java': 336,\n",
       " 'built': 335,\n",
       " 'care': 335,\n",
       " 'electronics': 335,\n",
       " 'winning': 335,\n",
       " 'las': 334,\n",
       " 'funds': 334,\n",
       " 'visa': 334,\n",
       " 'specific': 333,\n",
       " 'assembly': 333,\n",
       " 'developments': 333,\n",
       " 'polaroid': 333,\n",
       " 'changed': 332,\n",
       " 'extra': 332,\n",
       " 'helps': 332,\n",
       " 'included': 332,\n",
       " 'purchase': 332,\n",
       " 'technical': 331,\n",
       " 'model': 331,\n",
       " 'ram': 331,\n",
       " 'realize': 330,\n",
       " 'statement': 330,\n",
       " 'guess': 329,\n",
       " 'respect': 329,\n",
       " 'confidentiality': 329,\n",
       " 'appreciate': 328,\n",
       " 'managed': 328,\n",
       " 'moving': 328,\n",
       " 'exchange': 328,\n",
       " 'headquartered': 328,\n",
       " 'amount': 327,\n",
       " 'reset': 327,\n",
       " 'team': 327,\n",
       " 'en': 326,\n",
       " 'resource': 325,\n",
       " 'personal': 325,\n",
       " 'article': 325,\n",
       " 'worlds': 324,\n",
       " 'functions': 323,\n",
       " 'method': 323,\n",
       " 'max': 323,\n",
       " 'events': 322,\n",
       " 'vegas': 322,\n",
       " 'category': 322,\n",
       " 'pulse': 322,\n",
       " 'setting': 321,\n",
       " 'bilbo': 321,\n",
       " 'operating': 320,\n",
       " 'voice': 320,\n",
       " 'chance': 320,\n",
       " 'ma': 320,\n",
       " 'robotics': 320,\n",
       " 'stepper': 320,\n",
       " 'bbhttplovematchbzpc': 320,\n",
       " 'bbblmjb': 320,\n",
       " 'producer': 316,\n",
       " 'letter': 315,\n",
       " 'finally': 315,\n",
       " 'secure': 315,\n",
       " 'franklin': 315,\n",
       " 'batteries': 315,\n",
       " 'publiclistsapplecom': 315,\n",
       " 'bzb': 315,\n",
       " 'wanted': 314,\n",
       " 'todays': 314,\n",
       " 'break': 313,\n",
       " 'distance': 313,\n",
       " 'engaged': 313,\n",
       " 'gt': 312,\n",
       " 'dated': 312,\n",
       " 'styledmsospacerun': 312,\n",
       " 'wide': 311,\n",
       " 'rat': 311,\n",
       " 'verde': 311,\n",
       " 'providence': 311,\n",
       " 'sort': 310,\n",
       " 'marine': 310,\n",
       " 'ability': 309,\n",
       " 'michael': 308,\n",
       " 'external': 308,\n",
       " 'span': 308,\n",
       " 'interrupt': 307,\n",
       " 'worldwide': 307,\n",
       " 'stages': 307,\n",
       " 'growth': 306,\n",
       " 'markets': 306,\n",
       " 'clock': 306,\n",
       " 'phase': 306,\n",
       " 'tv': 305,\n",
       " 'item': 304,\n",
       " 'clear': 304,\n",
       " 'dynamic': 304,\n",
       " 'hightech': 304,\n",
       " 'mention': 303,\n",
       " 'relief': 303,\n",
       " 'penis': 303,\n",
       " 'hand': 302,\n",
       " 'worry': 302,\n",
       " 'div': 302,\n",
       " 'feminist': 302,\n",
       " 'mind': 301,\n",
       " 'step': 301,\n",
       " 'ph': 301,\n",
       " 'win': 300,\n",
       " 'avoid': 300,\n",
       " 'claim': 300,\n",
       " 'completed': 300,\n",
       " 'sperm': 300,\n",
       " 'gpd': 300,\n",
       " 'ps': 299,\n",
       " 'routine': 299,\n",
       " 'includes': 299,\n",
       " 'region': 299,\n",
       " 'inputs': 299,\n",
       " 'terms': 298,\n",
       " 'biology': 298,\n",
       " 'black': 298,\n",
       " 'cut': 297,\n",
       " 'follow': 296,\n",
       " 'fixed': 296,\n",
       " 'session': 296,\n",
       " 'estate': 296,\n",
       " 'paddingin': 296,\n",
       " 'ptheightin': 296,\n",
       " 'environment': 295,\n",
       " 'andor': 295,\n",
       " 'heard': 294,\n",
       " 'tests': 294,\n",
       " 'watsuncccolumbiaedu': 294,\n",
       " 'months': 293,\n",
       " 'cheers': 293,\n",
       " 'completion': 293,\n",
       " 'notice': 292,\n",
       " 'wouldnt': 292,\n",
       " 'references': 292,\n",
       " 'final': 292,\n",
       " 'wells': 292,\n",
       " 'respond': 291,\n",
       " 'annual': 291,\n",
       " 'sexual': 291,\n",
       " 'happened': 290,\n",
       " 'reported': 290,\n",
       " 'ready': 290,\n",
       " 'thursday': 290,\n",
       " 'accelerate': 290,\n",
       " 'difference': 289,\n",
       " 'direct': 289,\n",
       " 'analysis': 289,\n",
       " 'separator': 289,\n",
       " 'windo': 289,\n",
       " 'mit': 288,\n",
       " 'documentation': 288,\n",
       " 'figure': 288,\n",
       " 'ways': 288,\n",
       " 'minerals': 288,\n",
       " 'gapj': 288,\n",
       " 'styledwidthptbordertopnonebord': 288,\n",
       " 'erleft': 288,\n",
       " 'noneborderbottomsolid': 288,\n",
       " 'ptborderrightsolid': 288,\n",
       " 'msobordertopaltsolid': 288,\n",
       " 'ptmsoborderleftaltsolid': 288,\n",
       " 'wtext': 288,\n",
       " 'dept': 287,\n",
       " 'earth': 287,\n",
       " 'bill': 287,\n",
       " 'returns': 287,\n",
       " 'mac': 286,\n",
       " 'community': 286,\n",
       " 'inside': 286,\n",
       " 'vm': 286,\n",
       " 'wire': 286,\n",
       " 'plasma': 286,\n",
       " 'remote': 285,\n",
       " 'rest': 285,\n",
       " 'published': 285,\n",
       " 'structure': 285,\n",
       " 'skills': 285,\n",
       " 'ribbon': 285,\n",
       " 'terminal': 284,\n",
       " 'attention': 284,\n",
       " 'tabs': 284,\n",
       " 'reserves': 284,\n",
       " 'california': 283,\n",
       " 'ext': 283,\n",
       " 'social': 283,\n",
       " 'lower': 283,\n",
       " 'groups': 282,\n",
       " 'successful': 282,\n",
       " 'study': 282,\n",
       " 'car': 282,\n",
       " 'engine': 282,\n",
       " 'australia': 281,\n",
       " 'basic': 281,\n",
       " 'initial': 281,\n",
       " 'monthly': 281,\n",
       " 'picture': 281,\n",
       " 'inches': 281,\n",
       " 'trouble': 280,\n",
       " 'electronic': 280,\n",
       " 'kit': 280,\n",
       " 'rework': 280,\n",
       " 'pack': 279,\n",
       " 'encoder': 279,\n",
       " 'appear': 278,\n",
       " 'errors': 278,\n",
       " 'va': 278,\n",
       " 'tomorrow': 278,\n",
       " 'meaning': 278,\n",
       " 'advantage': 277,\n",
       " 'direction': 277,\n",
       " 'pick': 276,\n",
       " 'rich': 276,\n",
       " 'fdcwatsuncccolumbiaedu': 276,\n",
       " 'pwm': 276,\n",
       " 'thinking': 275,\n",
       " 'require': 275,\n",
       " 'kellystaolcom': 275,\n",
       " 'libraries': 274,\n",
       " 'header': 274,\n",
       " 'advanced': 274,\n",
       " 'projects': 274,\n",
       " 'pill': 274,\n",
       " 'september': 273,\n",
       " 'dos': 273,\n",
       " 'night': 273,\n",
       " 'tools': 272,\n",
       " 'star': 272,\n",
       " 'sciences': 272,\n",
       " 'provided': 271,\n",
       " 'downloading': 271,\n",
       " 'prize': 270,\n",
       " 'bbhttphipergirlcom': 270,\n",
       " 'appropriate': 269,\n",
       " 'contentlength': 269,\n",
       " 'wall': 269,\n",
       " 'mark': 268,\n",
       " 'pain': 268,\n",
       " 'da': 268,\n",
       " 'controller': 267,\n",
       " 'handle': 267,\n",
       " 'earliest': 267,\n",
       " 'masters': 267,\n",
       " 'ship': 267,\n",
       " 'robots': 267,\n",
       " 'paragraph': 266,\n",
       " 'english': 265,\n",
       " 'earlier': 265,\n",
       " 'attached': 265,\n",
       " 'staff': 265,\n",
       " 'street': 265,\n",
       " 'emerging': 265,\n",
       " 'cm': 265,\n",
       " 'downloaded': 264,\n",
       " 'road': 264,\n",
       " 'lowest': 264,\n",
       " 'pr': 264,\n",
       " 'jcf': 264,\n",
       " 'transfer': 263,\n",
       " 'agent': 262,\n",
       " 'instructions': 262,\n",
       " 'looked': 262,\n",
       " 'classes': 262,\n",
       " 'correctly': 261,\n",
       " 'late': 261,\n",
       " 'brought': 261,\n",
       " 'meds': 261,\n",
       " 'connection': 260,\n",
       " 'uk': 260,\n",
       " 'travel': 260,\n",
       " 'purpose': 259,\n",
       " 'compiler': 259,\n",
       " 'io': 259,\n",
       " 'steve': 259,\n",
       " 'overview': 259,\n",
       " 'registration': 259,\n",
       " 'foreign': 259,\n",
       " 'portfolio': 259,\n",
       " 'generate': 258,\n",
       " 'platform': 258,\n",
       " 'receiving': 258,\n",
       " 'larger': 258,\n",
       " 'wait': 257,\n",
       " 'easily': 257,\n",
       " 'topic': 257,\n",
       " 'sending': 257,\n",
       " 'eric': 256,\n",
       " 'mass': 256,\n",
       " 'white': 256,\n",
       " 'config': 256,\n",
       " 'dollars': 256,\n",
       " 'jeff': 256,\n",
       " 'grounded': 256,\n",
       " 'participants': 256,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Standard Libraries #####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### Step 1: Load the dataset and split it into training ham, training spam, and testing sets ####\n",
    "import os\n",
    "import email\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = './trec06p-cs280/data'\n",
    "\n",
    "# Load the labels\n",
    "labels = {}\n",
    "with open('./trec06p-cs280/labels', 'r') as f:\n",
    "    for line in f.read().splitlines():\n",
    "        label, file_path = line.split(' ', 1)\n",
    "        labels[file_path] = label\n",
    "\n",
    "# Load the emails into lists\n",
    "ham_emails = []\n",
    "spam_emails = []\n",
    "test_emails = []\n",
    "\n",
    "for folder in os.listdir(folder_path):\n",
    "    for file in os.listdir(os.path.join(folder_path, folder.zfill(3))):\n",
    "        with open(os.path.join(folder_path, folder, file), 'rb') as f:\n",
    "            msg = email.message_from_bytes(f.read())\n",
    "            if int(folder) <= 70:  # Folders 0-70 are for training\n",
    "                file_path = os.path.join('../data/', folder, file).replace(\"\\\\\",\"/\")\n",
    "                if labels[file_path] == 'ham':\n",
    "                    ham_emails.append(msg)\n",
    "                elif labels[file_path] == 'spam':\n",
    "                    spam_emails.append(msg)\n",
    "            elif int(folder) > 70:  # Folders 71-127 are for testing\n",
    "                test_emails.append(msg)\n",
    "\n",
    "#### Step 2: Extract the email bodies and remove alphanumeric characters and punctuation marks ####\n",
    "import re\n",
    "\n",
    "# Extract the email bodies\n",
    "ham_bodies = []\n",
    "spam_bodies = []\n",
    "test_bodies = []\n",
    "\n",
    "for msg in ham_emails:\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            body = part.get_payload()\n",
    "            body = body.lower()\n",
    "            body = re.sub(r'[^a-z\\s]', '', body) \n",
    "            ham_bodies.append(body)\n",
    "\n",
    "for msg in spam_emails:\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            body = part.get_payload()\n",
    "            body = body.lower()\n",
    "            body = re.sub(r'[^a-z\\s]', '', body) \n",
    "            spam_bodies.append(body)\n",
    "\n",
    "for msg in test_emails:\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            body = part.get_payload()\n",
    "            body = body.lower()\n",
    "            body = re.sub(r'[^a-z\\s]', '', body) \n",
    "            test_bodies.append(body)\n",
    "\n",
    "#### Step 3: Remove stop words ####\n",
    "with open('stop_words.txt', 'r') as f:\n",
    "    stop_words = set(f.read().splitlines())\n",
    "\n",
    "# Remove stop words from the email bodies\n",
    "ham_bodies = [' '.join([word for word in body.split() if word not in stop_words]) for body in ham_bodies]\n",
    "spam_bodies = [' '.join([word for word in body.split() if word not in stop_words]) for body in spam_bodies]\n",
    "test_bodies = [' '.join([word for word in body.split() if word not in stop_words]) for body in test_bodies]\n",
    "\n",
    "#### Step 4: Extract unique words and their frequencies ####\n",
    "from collections import Counter\n",
    "\n",
    "# Extract unique words and their frequencies from the ham and spam sets\n",
    "word_freq = Counter()\n",
    "for body in ham_bodies:\n",
    "    word_freq.update(body.split())\n",
    "for body in spam_bodies:\n",
    "    word_freq.update(body.split())\n",
    "\n",
    "word_freq = dict(word_freq.most_common(10000))\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da9278-9083-49b7-a950-d34743db38fc",
   "metadata": {},
   "source": [
    "***\n",
    "## Creating the feature matrices\n",
    "Create feature matrices for both the spam training set and ham training set with a dimensionality of 10000 (this was the specified number of different words in the dictionary). For each word in the dictionary, traverse through each file and check its occurrence. 1 denotes the existence of a word in the email and 0 otherwise. Thus, a matrix whose rows denote the number of files of training/testing set and columns denoting 10000 words will be generated. Every email in the training as a feature vector.<br>\n",
    "\n",
    "Consider that the higher the cardinality of the vocabulary, the higher the dimensionality of the matrix. The matrix grows with respect to the number of emails considered. Hence, slowing the program.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b1526d9d-fe35-46a2-b299-226bc17a1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the word indices\n",
    "word_indices = {word: i for i, word in enumerate(word_freq.keys())}\n",
    "\n",
    "# Create the feature matrices\n",
    "spam_feature_matrix = np.zeros((len(spam_bodies), 10000))\n",
    "ham_feature_matrix = np.zeros((len(ham_bodies), 10000))\n",
    "\n",
    "for i, body in enumerate(spam_bodies):\n",
    "    for word in body.split():\n",
    "        if word in word_indices:\n",
    "            spam_feature_matrix[i, word_indices[word]] = 1\n",
    "\n",
    "for i, body in enumerate(ham_bodies):\n",
    "    for word in body.split():\n",
    "        if word in word_indices:\n",
    "            ham_feature_matrix[i, word_indices[word]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fa7702e0-790b-4087-99dd-b5876e1dd75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_feature_matrix.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "671a8bfd-1fe8-4b68-bc2f-734a74294ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_feature_matrix.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edae964-ebda-4f51-a27c-0b006f6730b1",
   "metadata": {},
   "source": [
    "***\n",
    "## Computing the Priors\n",
    "The prior probabilities for spam and ham are computed by the following formula:\n",
    "\n",
    "$$ ùëÉ(ùëê = ‚Ñéùëéùëö) = \\frac {N_{ham}}{N_{doc}} $$\n",
    "$$ ùëÉ(ùëê = spùëéùëö) = \\frac {N_{spam}}{N_{doc}} $$\n",
    "\n",
    "Where $N_{ham}$ is the number of ham emails in the training set, $N_{spam}$ is the number of spam emails in the training set, and $N_{doc}$  is the total number of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a528608-4149-44f5-bebc-27c9eb94159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability of ham: 0.38825473890811424\n",
      "Prior probability of spam: 0.6117452610918858\n"
     ]
    }
   ],
   "source": [
    "# Compute the prior probabilities\n",
    "N_ham = len(ham_bodies)\n",
    "N_spam = len(spam_bodies)\n",
    "N_doc = N_ham + N_spam\n",
    "\n",
    "P_ham = N_ham / N_doc\n",
    "P_spam = N_spam / N_doc\n",
    "\n",
    "print(\"Prior probability of ham:\", P_ham)\n",
    "print(\"Prior probability of spam:\", P_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cfe4c-014b-411b-9341-05a21284cb48",
   "metadata": {},
   "source": [
    "***\n",
    "## Computing the Likelihood of each word + Laplace smoothing\n",
    "A vector containing the number of occurrences of each word in the dataset will be created. One vector will contain the number of occurrences of each word in the ham vocabulary and another vector for the spam vocabulary. Thus for word $w_{i}$, its probability of occurring as spam or ham is:\n",
    "\n",
    "$$ P(w_{i}|spam) = \\frac {count(w_{i},spam)} {\\sum_{w \\in V}count(w,spam)} $$\n",
    "$$ P(w_{i}|ham) = \\frac {count(w_{i},ham)} {\\sum_{w \\in V}count(w,ham)} $$\n",
    "\n",
    "Where $count(w_{i},spam)$ and $count(w_{i},ham)$ refer to the number of times the \n",
    "word appears in spam/ham dictionary and $\\sum_{w \\in V}count(w_{i},spam)$ and $\\sum_{w \\in V}count(w_{i},ham)$ refer to the total number of occurrences of each word in \n",
    "spam/ham emails. *Note*: $\\sum_{w \\in V}count(w,c)$ is not equal to the number of ham/spam messages, and it's not equal to the total number of unique words in spam/ham messages.<br>\n",
    "\n",
    "However, there are cases when we encounter a word in a dictionary which is not \n",
    "included in the trainset. In that case the probability of a word occurring given th \n",
    "classification will be 0 which will make the probability of the class given the word also equal to 0. To address the problem, lambda smoothing is introduced where a lambda is added to the numerator and add lambda times the number of words in the vocabulary. A slight modification to the formula above is added. For instance,\n",
    "\n",
    "$$ \n",
    "P(w_{i}|c) = \\frac {count(w_{i},c) + \\lambda} {\\sum_{w \\in V}count(w,c) + \\lambda|V|}\n",
    "$$\n",
    "\n",
    "Since we are adding a value $\\lambda$ in the numerator, $\\lambda|v|$ is added to the count of the documents belonging to the class in order to make the resultant sum of all the probabilities of words in the spam emails as one.\n",
    "\n",
    "If $\\lambda=1$, it‚Äôs called as laplace smoothing.\n",
    "\n",
    "We then have the following formula for computing the likelihoods of each word, with laplace smoothing.\n",
    "\n",
    "$$ \n",
    "P(w_{i}|spam) = \\frac {count(w_{i},spam) + \\lambda} {\\sum_{w \\in V}count(w,spam) + \\lambda|V|}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "P(w_{i}|ham) = \\frac {count(w_{i},ham) + \\lambda} {\\sum_{w \\in V}count(w,ham) + \\lambda|V|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8f7a8661-5ae7-4f34-910d-c4cd7c4d71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dictionaries for spam and ham word frequencies\n",
    "spam_word_freq = {}\n",
    "ham_word_freq = {}\n",
    "\n",
    "# Iterate through the word_freq dictionary and separate the word frequencies\n",
    "for word, count in word_freq.items():\n",
    "    if 1 in spam_feature_matrix[:, word_indices[word]]:\n",
    "        spam_word_freq[word] = count\n",
    "    elif 1 in ham_feature_matrix[:, word_indices[word]]:\n",
    "        ham_word_freq[word] = count\n",
    "\n",
    "lambda_val = 1  # Laplace smoothing parameter\n",
    "\n",
    "# Compute the likelihoods for each word in the spam vocabulary\n",
    "spam_likelihoods = {}\n",
    "total_count_spam = sum(spam_word_freq.values())\n",
    "for word in spam_word_freq.keys():\n",
    "    count_word_spam = word_freq.get(word, 0)\n",
    "    spam_likelihoods[word] = (count_word_spam + lambda_val) / (total_count_spam + lambda_val * len(spam_word_freq))\n",
    "\n",
    "# Compute the likelihoods for each word in the ham vocabulary\n",
    "ham_likelihoods = {}\n",
    "total_count_ham = sum(ham_word_freq.values())\n",
    "for word in ham_word_freq.keys():\n",
    "    count_word_ham = ham_word_freq.get(word, 0)\n",
    "    ham_likelihoods[word] = (count_word_ham + lambda_val) / (total_count_ham + lambda_val * len(ham_word_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "120d22d4-40c3-460d-94de-148ddaaec990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2994"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ea517-f4f6-468e-acca-715db7a06a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
